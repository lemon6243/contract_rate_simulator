import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
from sklearn.linear_model import LinearRegression 
from scipy.optimize import curve_fit 
import warnings
import io
import platform
from matplotlib import font_manager, rc 
import os 
# import shutil # ì˜¤ë¥˜ì˜ ì›ì¸ì´ ë˜ëŠ” í°íŠ¸ ìºì‹œ ì œê±° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë¡œì§ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ ì„¤ì •
warnings.filterwarnings('ignore')

# ----------------------------------------------------
# 0. í•œê¸€ í°íŠ¸ ì„¤ì • (V4.0 - Streamlit Cloud ì˜¤ë¥˜ ìˆ˜ì •)
# ----------------------------------------------------

def set_korean_font():
    # í°íŠ¸ ê²½ë¡œ ì§€ì • (GitHub/fonts/NanumGothic.ttf ê°€ì •)
    font_path_cloud = os.path.join(os.getcwd(), "fonts", "NanumGothic.ttf")
    
    if platform.system() == 'Windows':
        # (Windows ë¡œì»¬ í™˜ê²½)
        try:
            font_name = font_manager.FontProperties(fname="c:/Windows/Fonts/malgun.ttf").get_name()
            rc('font', family=font_name)
        except:
            rc('font', family='sans-serif')
    elif platform.system() == 'Darwin':
        # (Mac ë¡œì»¬ í™˜ê²½)
        rc('font', family='AppleGothic')
    else:
        # Streamlit Cloud (Linux) í™˜ê²½ ê°•ì œ ì ìš©
        # í°íŠ¸ íŒŒì¼ ë“±ë¡ ë° ì„¤ì •ë§Œ ë‚¨ê²¨ ì˜¤ë¥˜ë¥¼ í•´ê²°í•©ë‹ˆë‹¤.
        if os.path.exists(font_path_cloud):
            font_manager.fontManager.addfont(font_path_cloud)
            font_name_nanum = font_manager.FontProperties(fname=font_path_cloud).get_name()
            rc('font', family=font_name_nanum)
        else:
            # í°íŠ¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ fallback
            rc('font', family='sans-serif')
            
    plt.rcParams['axes.unicode_minus'] = False # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€
    
# í°íŠ¸ ì„¤ì • í•¨ìˆ˜ í˜¸ì¶œ
set_korean_font()

# ----------------------------------------------------

st.set_page_config(page_title="ì‚¬ìš©ê³„ì•½ë¥  í‰ê°€/ë¯¸ë˜ì˜ˆì¸¡ ì‹œë®¬ë ˆì´í„° (V4.0 - í˜¼í•© í‰ê°€ì§€í‘œ ì ìš©)", layout="wide")
st.title("ğŸ† ë„ì‹œê°€ìŠ¤ ì‚¬ìš©ê³„ì•½ë¥  í‰ê°€/ë¯¸ë˜ì˜ˆì¸¡ ì‹œë®¬ë ˆì´í„° (V4.0)")
st.caption("Gapê³¼ ì ˆëŒ€ ê³„ì•½ë¥ ì„ **í˜¼í•©**í•˜ì—¬ **911ì  ì¶©ì¡±**ì„ ìœ„í•œ ìµœì  ë°°ì  ë¹„ìœ¨ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.")

# ----------------------------------------------------
# 1. ê³ ì • KPI ë° ê¸°ë³¸ í™˜ê²½ ì„¤ì •
# ----------------------------------------------------
st.sidebar.header("ğŸ¯ í‰ê°€ ëª©í‘œ ë° ê³ ì • ê¸°ì¤€")
st.sidebar.markdown(f"**2026ë…„ í‰ê°€ ì‹œì :** **2026ë…„ 12ì›” ì˜ˆì¸¡**")
st.sidebar.markdown(f"**ê³„ì•½ ìœ ì§€ ì ˆëŒ€ ê¸°ì¤€:** **911ì **")
st.sidebar.markdown("---")

# 2026ë…„ ì‹ ê·œ í‰ê°€ ì§€í‘œ ë°°ì  (ì´ 900ì )
SCORE_WEIGHTS = {
    "ì•ˆì „ì ê²€(ì‹¤ì ê²€ë¥ )": 500,
    "ì¤‘ì ê³ ê°ì ê²€(ë³´ì¼ëŸ¬)": 100,
    "ìƒë‹´ì‘ëŒ€ìœ¨": 100,
    "ìƒë‹´ê¸°ì—¬ìœ¨": 100,
    "ê³ ê°ë§Œì¡±ë„": 100,
}
PERCENTAGE_COLUMNS = ["ì•ˆì „ì ê²€(ì‹¤ì ê²€ë¥ )", "ì¤‘ì ê³ ê°ì ê²€(ë³´ì¼ëŸ¬)", "ìƒë‹´ì‘ëŒ€ìœ¨", "ìƒë‹´ê¸°ì—¬ìœ¨"]
SCORE_COLUMN = "ê³ ê°ë§Œì¡±ë„" 

OTHER_SCORE_COLUMNS = list(SCORE_WEIGHTS.keys())
OTHER_SCORE_MAX_SUM = sum(SCORE_WEIGHTS.values()) # 900ì 

GOALS = {
    2026: 90.0
}

st.sidebar.markdown(f"##### 2026ë…„ ê³„ì•½ë¥  ëª©í‘œ: **{GOALS[2026]}%**")
st.sidebar.markdown(f"##### ê¸°íƒ€ ì§€í‘œ ì´ì  Max: **{OTHER_SCORE_MAX_SUM}ì **")
st.sidebar.markdown("---")


# --- ğŸŒŸ ì‚¬ìš©ê³„ì•½ë¥  100ì  ì§€í‘œ ë°°ì  ë¡œì§ ì„¤ì • ---
st.sidebar.subheader("ğŸ’¯ ì‚¬ìš©ê³„ì•½ë¥  100ì  í‰ê°€ì§€í‘œ êµ¬ì„± (V4.0)")

# 1. í˜¼í•© í‰ê°€ì§€í‘œ ë¹„ìœ¨ ì„¤ì •
st.sidebar.markdown("##### 1. Gap ë° ì ˆëŒ€ ê³„ì•½ë¥  ë¹„ìœ¨ ì„¤ì • (í•©ì‚° 100%)")
gap_ratio = st.sidebar.slider("Gap í‰ê°€ì§€í‘œ ë¹„ìœ¨ (%)", min_value=0, max_value=100, value=50, step=10)
abs_rate_ratio = 100 - gap_ratio
st.sidebar.info(f"ğŸ‘‰ **Gap ë¹„ìœ¨: {gap_ratio}%** (100ì  ì¤‘ {gap_ratio}ì  ë°˜ì˜)")
st.sidebar.info(f"ğŸ‘‰ **ì ˆëŒ€ ê³„ì•½ë¥  ë¹„ìœ¨: {abs_rate_ratio}%** (100ì  ì¤‘ {abs_rate_ratio}ì  ë°˜ì˜)")
st.sidebar.markdown("---")

# 2. Gap ê¸°ì¤€ ì„¤ì •
st.sidebar.markdown("##### 2. Gap ê¸°ì¤€ ì ìˆ˜ (Max 100ì )")
target_goal = st.sidebar.number_input("ëª©í‘œ ê¸°ì¤€ ê³„ì•½ë¥  (%)", value=GOALS[2026], min_value=90.0, max_value=100.0, step=0.1)
DEFAULT_BINS_STR = "-1, 0.0, 3.0, 5.0, 7.0, 9.0, 11.0, 13.0, 15.0, 17.0, 19.0, 20.0, 100" 
DEFAULT_LABELS_STR = "100, 97, 94, 88, 85, 82, 79, 76, 73, 70, 0, 0" 
bins_input = st.sidebar.text_input("Gap ê²½ê³„ê°’ (%, ì‰¼í‘œ êµ¬ë¶„)", value=DEFAULT_BINS_STR)
labels_input = st.sidebar.text_input("Gap ë¶€ì—¬ ì ìˆ˜ (Max 100ì )", value=DEFAULT_LABELS_STR)
st.sidebar.markdown("---")

# 3. ì ˆëŒ€ ê³„ì•½ë¥  ê¸°ì¤€ ì„¤ì •
st.sidebar.markdown("##### 3. ì ˆëŒ€ ê³„ì•½ë¥  ê¸°ì¤€ ì ìˆ˜ (Max 100ì )")
abs_rate_bins_str = st.sidebar.text_area(
    "ì ˆëŒ€ ê³„ì•½ë¥  ê²½ê³„ê°’ (%, ì‰¼í‘œ êµ¬ë¶„, ì˜ˆ: 80, 85, 90, 95)", 
    value="0, 80.0, 85.0, 90.0, 93.0, 100"
)
abs_rate_labels_str = st.sidebar.text_area(
    "ì ˆëŒ€ ê³„ì•½ë¥  ë¶€ì—¬ ì ìˆ˜ (Max 100ì , ê²½ê³„ê°’-1)", 
    value="70, 80, 85, 95, 100"
)
st.sidebar.markdown("---")


# ----------------------------------------------------
# 2. ë°ì´í„° ì²˜ë¦¬ ë° ì˜ˆì¸¡ í•¨ìˆ˜ (V3.6 - ë¡œì§€ìŠ¤í‹± ì„±ì¥ ê³¡ì„ )
# ----------------------------------------------------

def extract_year_month(s):
    # í…ìŠ¤íŠ¸ì—ì„œ ì—°ë„ì™€ ì›” ì¶”ì¶œ
    numbers = re.findall(r'(\d{4}|\d{1,2})', s)
    if not numbers:
        return (0, 0)
    year_part = int(numbers[0])
    if year_part < 100 and year_part > 20: 
        year_part += 2000 
    
    month_part = int(numbers[1]) if len(numbers) > 1 else 0
    return (year_part, month_part)

# ë¡œì§€ìŠ¤í‹± ì„±ì¥ í•¨ìˆ˜ ì •ì˜
def logistic_func(t, k, t0):
    L = 1.0 
    k = np.clip(k, None, 10.0) 
    return L / (1 + np.exp(-k * (t - t0)))

def predict_rates_logistic(df_rate, rate_cols, future_year):
    years = np.array([extract_year_month(c)[0] + extract_year_month(c)[1]/12 for c in rate_cols])
    future_year_float = future_year + 11/12
    prediction_col_name = f"ì˜ˆì¸¡_{future_year}ë…„_12ì›”"
    pred_list = []
    
    df_rate_float = df_rate[rate_cols].copy() / 100 

    for idx, row in df_rate_float.iterrows():
        y = row.values.astype(float)
        x = years.reshape(-1, 1)
        valid_idx = ~np.isnan(y) & (y > 0.001) 
        x_valid, y_valid = x[valid_idx].flatten(), y[valid_idx]
        
        pred_rate_pct = np.nan
        
        if len(y_valid) >= 5: 
            try:
                p0_initial = [0.5, x_valid.mean()]
                popt, pcov = curve_fit(logistic_func, x_valid, y_valid, 
                                     p0=p0_initial, maxfev=5000, 
                                     bounds=((-np.inf, x_valid.min()), (np.inf, x_valid.max() + 5)))
                
                k_opt, t0_opt = popt
                
                pred_raw = logistic_func(future_year_float, k_opt, t0_opt)
                pred_rate_pct = np.clip(pred_raw * 100, 0, 100)
                
            except Exception as e:
                # ì„ í˜• íšŒê·€ë¡œ Fallback (ì•ˆì •ì„± í™•ë³´)
                if len(y_valid) >= 2:
                    model = LinearRegression().fit(x_valid.reshape(-1, 1), y_valid)
                    pred_raw_linear = model.predict(np.array([future_year_float]).reshape(-1,1))[0]
                    pred_rate_pct = np.clip(pred_raw_linear * 100, 0, 100)
                elif len(y_valid) == 1:
                    pred_rate_pct = np.clip(y_valid[-1] * 100, 0, 100)
                
        elif len(y_valid) >= 2:
            model = LinearRegression().fit(x_valid.reshape(-1, 1), y_valid)
            pred_raw_linear = model.predict(np.array([future_year_float]).reshape(-1,1))[0]
            pred_rate_pct = np.clip(pred_raw_linear * 100, 0, 100)
        elif len(y_valid) == 1:
            pred_rate_pct = np.clip(y_valid[-1] * 100, 0, 100)
        
        pred_list.append(pred_rate_pct)
        
    pred_df = pd.DataFrame({
        "ì„¼í„°ëª…": df_rate["ì„¼í„°ëª…"],
        prediction_col_name: np.array(pred_list)
    })
    return pred_df.round(2)


# í‰ê°€ ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜ (V4.0 - í˜¼í•© í‰ê°€ì§€í‘œ ë¡œì§ ì¶”ê°€)
def calculate_score_2026_v4(data, predicted_col, target_goal, 
                          gap_bins_list, gap_labels_list, 
                          abs_bins_list, abs_labels_list, 
                          gap_ratio, abs_rate_ratio,
                          df_other_score_data, score_weights):
    
    result = data[["ì„¼í„°ëª…", predicted_col]].copy().rename(columns={predicted_col: "ì˜ˆì¸¡ê³„ì•½ë¥ "})
    
    # --- 900ì  ê¸°íƒ€ ì§€í‘œ ì ìˆ˜ ê³„ì‚° ë° ë³‘í•© ---
    DEFAULT_RATE = 95 
    DEFAULT_SCORE = 95
    
    if df_other_score_data is not None and not df_other_score_data.empty:
        result = result.merge(df_other_score_data, on="ì„¼í„°ëª…", how="left")
        
        calculated_scores = []
        for index, row in result.iterrows():
            total_score = 0
            for col in PERCENTAGE_COLUMNS:
                weight = score_weights[col]
                rate = row.get(col)
                if pd.isna(rate):
                    score = weight * (DEFAULT_RATE / 100)
                    result.loc[index, col] = DEFAULT_RATE
                else:
                    rate = np.clip(rate, 0, 100)
                    score = weight * (rate / 100)
                total_score += score
            
            col = SCORE_COLUMN
            score = row.get(col)
            if pd.isna(score):
                score_value = DEFAULT_SCORE
                result.loc[index, col] = DEFAULT_SCORE
            else:
                score_value = np.clip(score, 0, score_weights[col])
            
            total_score += score_value
            calculated_scores.append(round(total_score))

        result["ê¸°íƒ€ ì§€í‘œ ì´ì  (Max 900ì )"] = calculated_scores
        result["ê¸°íƒ€ ì§€í‘œ ì´ì  (Max 900ì )"] = result["ê¸°íƒ€ ì§€í‘œ ì´ì  (Max 900ì )"].astype(int)
        
    else:
        result["ê¸°íƒ€ ì§€í‘œ ì´ì  (Max 900ì )"] = round(OTHER_SCORE_MAX_SUM * (DEFAULT_RATE / 100))
        for col in PERCENTAGE_COLUMNS:
             result[col] = DEFAULT_RATE
        result[SCORE_COLUMN] = DEFAULT_SCORE
    
    
    # --- 1. Gap ê¸°ì¤€ ì ìˆ˜ ì‚°ì • (Max 100ì ) ---
    result["Gap(%)"] = np.clip(target_goal - result["ì˜ˆì¸¡ê³„ì•½ë¥ "], 0, None).round(2)
    
    # Gapì— ë”°ë¥¸ 100ì  ë§Œì  ì ìˆ˜ ë¶€ì—¬
    gap_score_raw = pd.cut(
        result["Gap(%)"],
        bins=gap_bins_list,
        labels=gap_labels_list,
        ordered=False 
    ).astype(float).fillna(0)
    
    result["Gap ê¸°ì¤€ ì ìˆ˜"] = np.clip(gap_score_raw, 0, 100).astype(int)
    
    
    # --- 2. ì ˆëŒ€ ê³„ì•½ë¥  ê¸°ì¤€ ì ìˆ˜ ì‚°ì • (Max 100ì ) ---
    abs_rate_score_raw = pd.cut(
        result["ì˜ˆì¸¡ê³„ì•½ë¥ "], 
        bins=abs_bins_list,
        labels=abs_labels_list,
        ordered=True 
    ).astype(float).fillna(0)
    
    result["ì ˆëŒ€ ê³„ì•½ë¥  ê¸°ì¤€ ì ìˆ˜"] = np.clip(abs_rate_score_raw, 0, 100).astype(int)

    
    # --- 3. ìµœì¢… ì‚¬ìš©ê³„ì•½ë¥  ì ìˆ˜ (í˜¼í•© ë¡œì§) ---
    # ìµœì¢… ì ìˆ˜ = (Gap ê¸°ì¤€ ì ìˆ˜ * Gap ë¹„ìœ¨) + (ì ˆëŒ€ ê³„ì•½ë¥  ê¸°ì¤€ ì ìˆ˜ * ì ˆëŒ€ ê³„ì•½ë¥  ë¹„ìœ¨)
    result["ì‚¬ìš©ê³„ì•½ë¥  ì ìˆ˜ (Max 100ì )"] = (
        (result["Gap ê¸°ì¤€ ì ìˆ˜"] * gap_ratio / 100) + 
        (result["ì ˆëŒ€ ê³„ì•½ë¥  ê¸°ì¤€ ì ìˆ˜"] * abs_rate_ratio / 100)
    ).round(0).astype(int)
        
    # --- 4. ìµœì¢… í‰ê°€ ê²°ê³¼ ë¶„ì„ ---
    result["ì´ì  (Max 1000ì )"] = result["ê¸°íƒ€ ì§€í‘œ ì´ì  (Max 900ì )"] + result["ì‚¬ìš©ê³„ì•½ë¥  ì ìˆ˜ (Max 100ì )"]
    result["911ì  ë„ë‹¬ ì—¬ë¶€"] = np.where(result["ì´ì  (Max 1000ì )"] >= 911, "âœ… ë„ë‹¬", "âŒ ìœ„í—˜")
    
    return result

# ----------------------------------------------------
# 3. ë°ì´í„° ë¡œë“œ ë° ì‹¤í–‰
# ----------------------------------------------------
st.header("1. ì„¼í„°ë³„ ê³„ì•½ë¥  ë°ì´í„° ë° ê¸°íƒ€ ì§€í‘œ ì ìˆ˜ ì…ë ¥")

# --- ê¸°íƒ€ ì§€í‘œ 900ì  íŒŒì¼ ì—…ë¡œë“œ ì–‘ì‹ ì œê³µ ---
st.subheader("1-1. ê¸°íƒ€ ì§€í‘œ (900ì ) í•­ëª©ë³„ ë¹„ìœ¨/ì ìˆ˜ ì…ë ¥ ì–‘ì‹")
template_data = {
    "ì„¼í„°ëª…": ["ì¥ì•ˆ", "ì„œë¶€ì„¼í„°", "ë™ë¶€ì„¼í„°"],
    "ì•ˆì „ì ê²€(ì‹¤ì ê²€ë¥ )": [91, 95, 98],
    "ì¤‘ì ê³ ê°ì ê²€(ë³´ì¼ëŸ¬)": [95, 90, 95],
    "ìƒë‹´ì‘ëŒ€ìœ¨": [98, 100, 99],
    "ìƒë‹´ê¸°ì—¬ìœ¨": [92, 98, 97],
    "ê³ ê°ë§Œì¡±ë„": [96.0, 95.5, 98.2],
}
df_template = pd.DataFrame(template_data)

towrite = io.BytesIO()
df_template.to_excel(towrite, index=False, engine='openpyxl')
towrite.seek(0)

st.download_button(
    "ğŸ“¥ ê¸°íƒ€ ì§€í‘œ í•­ëª©ë³„ ë¹„ìœ¨/ì ìˆ˜ ì…ë ¥ ì–‘ì‹ ë‹¤ìš´ë¡œë“œ (Excel)", 
    data=towrite.getvalue(), 
    file_name="ê¸°íƒ€_ì§€í‘œ_í•­ëª©ë³„_ë¹„ìœ¨_ì ìˆ˜_ì…ë ¥ì–‘ì‹.xlsx", 
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    help="ë‹¤ìš´ë¡œë“œ í›„ 4ê°œ í•­ëª©ì€ ë¹„ìœ¨(%)ì„, **ê³ ê°ë§Œì¡±ë„**ëŠ” **ì‹¤ìˆ˜ ì ìˆ˜**ë¥¼ ì…ë ¥í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”."
)

st.markdown("---")

# --- ê¸°íƒ€ ì§€í‘œ 900ì  íŒŒì¼ ì—…ë¡œë“œ ---
other_score_file = st.file_uploader(
    "1-2. ì„¼í„°ë³„ ê¸°íƒ€ ì§€í‘œ ì´ì  (Max 900ì ) í•­ëª©ë³„ ë¹„ìœ¨/ì ìˆ˜ íŒŒì¼ ì—…ë¡œë“œ", 
    type=["xlsx", "csv"],
    key="other_score_file"
)

df_other_score_rates = None
if other_score_file:
    try:
        if other_score_file.name.endswith('.csv'):
            df_raw_other = pd.read_csv(other_score_file)
        else: 
            df_raw_other = pd.read_excel(other_score_file, sheet_name=0)
        
        df_raw_other.columns = df_raw_other.columns.astype(str).str.strip()
        center_col_other_candidates = [c for c in df_raw_other.columns if "ì„¼í„°" in c or "ì§€ì " in c or "êµ¬ë¶„" in c]
        if not center_col_other_candidates:
             raise ValueError("ì„¼í„°ëª… ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        center_col_other = center_col_other_candidates[0]
        
        df_raw_other["ì„¼í„°ëª…_temp"] = df_raw_other[center_col_other].astype(str).str.strip()
        df_raw_other = df_raw_other[
            ~df_raw_other["ì„¼í„°ëª…_temp"].str.contains('í•©ê³„|ì´ê³„', case=False, na=False)
        ].drop(columns=["ì„¼í„°ëª…_temp"])
        
        if df_raw_other.empty:
            st.warning("âš ï¸ ê¸°íƒ€ ì§€í‘œ íŒŒì¼ì—ì„œ 'í•©ê³„', 'ì´ê³„' ë¡œìš°ë¥¼ ì œì™¸í•œ í›„ ìœ íš¨í•œ ì„¼í„° ë°ì´í„°ê°€ ë‚¨ì•„ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
            df_other_score_rates = None
            st.stop()
        
        cols_to_use = [center_col_other] + OTHER_SCORE_COLUMNS
        cols_in_file = [c for c in cols_to_use if c in df_raw_other.columns] 
        
        df_other_score_rates = df_raw_other[cols_in_file].rename(columns={center_col_other: "ì„¼í„°ëª…"})
        df_other_score_rates["ì„¼í„°ëª…"] = df_other_score_rates["ì„¼í„°ëª…"].astype(str).str.strip()
        for col in OTHER_SCORE_COLUMNS:
            if col in df_other_score_rates.columns:
                df_other_score_rates[col] = pd.to_numeric(df_other_score_rates[col], errors='coerce')
        df_other_score_rates = df_other_score_rates.drop_duplicates(subset=["ì„¼í„°ëª…"]).reset_index(drop=True)
        st.success("âœ… ì„¼í„°ë³„ ê¸°íƒ€ ì§€í‘œ í•­ëª©ë³„ ë¹„ìœ¨/ì ìˆ˜ ë¡œë“œ ë° 'í•©ê³„/ì´ê³„' ë¡œìš° ì •ë¦¬ ì™„ë£Œ.")
    except Exception as e:
        st.error(f"ğŸš¨ ê¸°íƒ€ ì§€í‘œ íŒŒì¼ ë¡œë“œ ë° í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        df_other_score_rates = None

if df_other_score_rates is None or df_other_score_rates.empty:
    st.info(f"âš ï¸ ê¸°íƒ€ ì§€í‘œ í•­ëª©ë³„ ë¹„ìœ¨/ì ìˆ˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì•¼ ì •í™•íˆ ê³„ì‚°ë©ë‹ˆë‹¤. í˜„ì¬ëŠ” ëª¨ë“  ì„¼í„°ì— **ì „ í•­ëª© 95%**ê°€ ì„ì‹œ ì ìš©ë˜ì–´ **ì´ì  855ì **ìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤.")

st.markdown("---")

# --- ì‚¬ìš©ê³„ì•½ë¥  íŒŒì¼ ì—…ë¡œë“œ ---
st.subheader("1-3. ì„¼í„°ë³„ ëˆ„ì  ì‚¬ìš©ê³„ì•½ë¥  ë°ì´í„°")
uploaded_file = st.file_uploader(
    "ì„¼í„°ë³„ ëˆ„ì  ì‚¬ìš©ê³„ì•½ë¥  ì—‘ì…€ íŒŒì¼ (.xlsx ë˜ëŠ” .csv) ì—…ë¡œë“œ", 
    type=["xlsx", "csv"],
    key="rate_file"
)

if uploaded_file:
    try:
        if uploaded_file.name.endswith('.csv'):
            df_raw = pd.read_csv(uploaded_file)
        else: 
            df_raw = pd.read_excel(uploaded_file, sheet_name=0)
    except Exception as e:
        st.error(f"ğŸš¨ ì‚¬ìš©ê³„ì•½ë¥  íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.stop()

    df_raw.columns = df_raw.columns.astype(str).str.strip()
    center_candidates = [c for c in df_raw.columns if ("ì„¼í„°" in c or "ì§€ì " in c or "êµ¬ë¶„" in c)]
    col_center = center_candidates[0] if center_candidates else df_raw.columns[0]
    col_center = st.selectbox("ì„¼í„°ëª…/êµ¬ë¶„ ì»¬ëŸ¼ ì„ íƒ", df_raw.columns, index=df_raw.columns.get_loc(col_center))
    
    rate_cols_candidates = [c for c in df_raw.columns if c != col_center and re.search(r'\d{4}|\d{2}ë…„|\%', c)]
    if not rate_cols_candidates:
        st.error("ğŸš¨ ê³„ì•½ë¥  ë°ì´í„°ë¡œ ì¸ì‹í•  ìˆ˜ ìˆëŠ” ì»¬ëŸ¼(ì˜ˆ: '24ë…„ 02ì›”', 'ì²´ê²°ë¥ ')ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    rate_cols_sorted = sorted(rate_cols_candidates, key=extract_year_month)
    latest_col = rate_cols_sorted[-1]
    
    data_analysis = df_raw[[col_center] + rate_cols_sorted].rename(columns={col_center: "ì„¼í„°ëª…"})
    data_analysis["ì„¼í„°ëª…"] = data_analysis["ì„¼í„°ëª…"].astype(str).str.strip()
    
    for c in rate_cols_sorted:
        data_analysis[c] = pd.to_numeric(
            data_analysis[c].astype(str).str.replace("%", "").str.replace(",", ""), 
            errors='coerce'
        )
        data_analysis[c] = np.where(
            (data_analysis[c] > 0.001) & (data_analysis[c] <= 1.00), 
            data_analysis[c] * 100, 
            data_analysis[c]
        )
        data_analysis[c] = np.clip(data_analysis[c].fillna(0), 0, 100)
        
    st.success(f"âœ… ì‚¬ìš©ê³„ì•½ë¥  ë°ì´í„° ë¡œë“œ ì™„ë£Œ. ìµœì‹  ê³„ì•½ë¥  ì»¬ëŸ¼: **{latest_col}**")
    
    
    # ----------------------------------------------------
    # 4. í‰ê°€ ê¸°ì¤€ ìœ íš¨ì„± ê²€ì‚¬ ë° ë°ì´í„° ì¤€ë¹„
    # ----------------------------------------------------
    valid_criteria = True
    try:
        gap_bins_list = [float(x.strip()) for x in bins_input.split(',') if x.strip()]
        gap_labels_list = [float(x.strip()) for x in labels_input.split(',') if x.strip()]
        
        if -1 not in gap_bins_list: gap_bins_list.insert(0, -1)
        gap_bins_list = sorted(list(set(gap_bins_list))) 
        gap_labels_list = [int(l) for l in gap_labels_list] 
        
        if len(gap_bins_list) - 1 != len(gap_labels_list):
            st.sidebar.error("Gap ê²½ê³„ê°’ê³¼ ë¶€ì—¬ ì ìˆ˜ì˜ ê°œìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (ê²½ê³„ê°’-1 = ì ìˆ˜ ê°œìˆ˜)")
            valid_criteria = False
            
        abs_rate_bins_str = abs_rate_bins_str.replace('[', '').replace(']', '') 
        abs_rate_labels_str = abs_rate_labels_str.replace('[', '').replace(']', '')
            
        abs_rate_bins_list = [float(x.strip()) for x in abs_rate_bins_str.split(',') if x.strip()]
        abs_rate_labels_list = [float(x.strip()) for x in abs_rate_labels_str.split(',') if x.strip()]
        
        if len(abs_rate_bins_list) - 1 != len(abs_rate_labels_list):
            st.sidebar.error("ì ˆëŒ€ ê³„ì•½ë¥  ê²½ê³„ê°’ê³¼ ë¶€ì—¬ ì ìˆ˜ì˜ ê°œìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (ê²½ê³„ê°’-1 = ì ìˆ˜ ê°œìˆ˜)")
            valid_criteria = False

        abs_rate_labels_list = [int(l) for l in abs_rate_labels_list]

    except ValueError:
        st.sidebar.error("êµ¬ê°„ ê²½ê³„ê°’ ë˜ëŠ” ë¶€ì—¬ ì ìˆ˜ë¥¼ ì˜¬ë°”ë¥¸ ìˆ«ìë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        valid_criteria = False

    if valid_criteria:
        # ----------------------------------------------------
        # 5. ë¯¸ë˜ ì˜ˆì¸¡ ë° í‰ê°€ ì ìˆ˜ ì‹œë®¬ë ˆì´ì…˜
        # ----------------------------------------------------
        
        # 5-1. 2026ë…„ 12ì›” ì˜ˆì¸¡ (ë¡œì§€ìŠ¤í‹± í•¨ìˆ˜ ì‚¬ìš©)
        target_year = 2026
        pred_df = predict_rates_logistic(data_analysis, rate_cols_sorted, target_year)
        predicted_col_name = f"ì˜ˆì¸¡_{target_year}ë…„_12ì›”"
        data_merged = data_analysis.merge(pred_df, on="ì„¼í„°ëª…", how="left")
        
        # 5-2. 2026ë…„ ì˜ˆì¸¡ì¹˜ ê¸°ë°˜ í‰ê°€ ì ìˆ˜ ì‹œë®¬ë ˆì´ì…˜ (V4.0 í˜¼í•© ë¡œì§ ì‚¬ìš©)
        final_score_df = calculate_score_2026_v4(
            data_merged, predicted_col_name, target_goal, 
            gap_bins_list, gap_labels_list, 
            abs_bins_list, abs_labels_list, 
            gap_ratio, abs_rate_ratio,
            df_other_score_rates, SCORE_WEIGHTS
        )
        
        # ----------------------------------------------------
        # 6. ìµœì¢… ë¶„ì„ ê²°ê³¼ ë° ì‹œê°í™”
        # ----------------------------------------------------
        st.markdown("---")
        st.header(f"ğŸ” 2026ë…„ 12ì›” ì˜ˆì¸¡ í‰ê°€ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ (V4.0 - í˜¼í•© í‰ê°€ì§€í‘œ ì ìš©)")

        # 6-1. ê²°ê³¼í‘œ (í•µì‹¬ ì •ë³´)
        core_cols = (
            ["ì„¼í„°ëª…"] + OTHER_SCORE_COLUMNS + 
            ["ê¸°íƒ€ ì§€í‘œ ì´ì  (Max 900ì )", "ì˜ˆì¸¡ê³„ì•½ë¥ ", "Gap(%)", "Gap ê¸°ì¤€ ì ìˆ˜", 
             "ì ˆëŒ€ ê³„ì•½ë¥  ê¸°ì¤€ ì ìˆ˜", "ì‚¬ìš©ê³„ì•½ë¥  ì ìˆ˜ (Max 100ì )", 
             "ì´ì  (Max 1000ì )", "911ì  ë„ë‹¬ ì—¬ë¶€"]
        )
        
        st.subheader("1. ì„¼í„°ë³„ 2026ë…„ 12ì›” ì˜ˆì¸¡ ê³„ì•½ë¥  ë° í‰ê°€ ì ìˆ˜ ì¢…í•©í‘œ")
        
        # Streamlit Dataframe Column Config
        column_config = {
            "ì•ˆì „ì ê²€(ì‹¤ì ê²€ë¥ )": st.column_config.NumberColumn("ì•ˆì „ì ê²€(%)", format="%.2f"),
            "ì¤‘ì ê³ ê°ì ê²€(ë³´ì¼ëŸ¬)": st.column_config.NumberColumn("ì¤‘ì ê³ ê°(%)", format="%.2f"),
            "ìƒë‹´ì‘ëŒ€ìœ¨": st.column_config.NumberColumn("ì‘ëŒ€ìœ¨(%)", format="%.2f"),
            "ìƒë‹´ê¸°ì—¬ìœ¨": st.column_config.NumberColumn("ê¸°ì—¬ìœ¨(%)", format="%.2f"),
            "ê³ ê°ë§Œì¡±ë„": st.column_config.NumberColumn("ë§Œì¡±ë„(ì )", format="%.2fì "),
            "ì˜ˆì¸¡ê³„ì•½ë¥ ": st.column_config.NumberColumn("ì˜ˆì¸¡ê³„ì•½ë¥ (%)", format="%.2f%%"),
            "Gap(%)": st.column_config.NumberColumn("Gap(%)", format="%.2f%%"),
            "Gap ê¸°ì¤€ ì ìˆ˜": st.column_config.NumberColumn("Gap ì ìˆ˜", format="%dì "),
            "ì ˆëŒ€ ê³„ì•½ë¥  ê¸°ì¤€ ì ìˆ˜": st.column_config.NumberColumn("ì ˆëŒ€ìœ¨ ì ìˆ˜", format="%dì "),
            "ì‚¬ìš©ê³„ì•½ë¥  ì ìˆ˜ (Max 100ì )": st.column_config.NumberColumn("ê³„ì•½ë¥  ì´ì ", format="%dì "),
            "ê¸°íƒ€ ì§€í‘œ ì´ì  (Max 900ì )": st.column_config.NumberColumn("900ì  ì´ì ", format="%dì "),
            "ì´ì  (Max 1000ì )": st.column_config.NumberColumn("ìµœì¢… ì´ì ", format="%dì "),
        }
        
        valid_centers_df = final_score_df.dropna(subset=OTHER_SCORE_COLUMNS, how='all').copy()
        valid_centers_df = valid_centers_df[
            ~valid_centers_df["ì„¼í„°ëª…"].str.contains('í•©ê³„|ì´ê³„', case=False, na=False)
        ]

        st.dataframe(valid_centers_df[core_cols].sort_values("ì´ì  (Max 1000ì )", ascending=False).reset_index(drop=True), 
                     use_container_width=True,
                     column_config=column_config)

        # 6-2. 911ì  ë„ë‹¬ ë¦¬ìŠ¤í¬ ì§„ë‹¨ ë° ì„œë¶€ì„¼í„° ê¸°ì¤€ ë¶„ì„
        st.subheader("2. 911ì  ë„ë‹¬ ë¦¬ìŠ¤í¬ ì§„ë‹¨ ë° 'ì„œë¶€ì„¼í„°' ë¶„ì„")
        
        # 911ì  ë¦¬ìŠ¤í¬ ì§„ë‹¨
        risk_911 = valid_centers_df[valid_centers_df["911ì  ë„ë‹¬ ì—¬ë¶€"] == "âŒ ìœ„í—˜"].copy()
        risk_count = len(risk_911)
        if risk_count > 0:
            st.error(f"âš ï¸ **ê³„ì•½ ìœ ì§€ ìœ„í—˜ ì„¼í„° ({risk_count}ê³³):** 2026ë…„ 12ì›” ì˜ˆì¸¡ì¹˜ë¡œ í‰ê°€í–ˆì„ ë•Œ **911ì  ë¯¸ë§Œ**ì…ë‹ˆë‹¤.")
            st.dataframe(risk_911[["ì„¼í„°ëª…", "ì˜ˆì¸¡ê³„ì•½ë¥ ", "ê¸°íƒ€ ì§€í‘œ ì´ì  (Max 900ì )", "ì´ì  (Max 1000ì )"]].sort_values("ì´ì  (Max 1000ì )"))
        else:
            st.success("âœ… 2026ë…„ 12ì›” ì˜ˆì¸¡ì¹˜ë¡œ í‰ê°€í–ˆì„ ë•Œ ëª¨ë“  ì„¼í„°ê°€ 911ì (ê³„ì•½ ìœ ì§€ ê¸°ì¤€)ì— ë„ë‹¬ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

        # ì„œë¶€ì„¼í„° ë¶„ì„ (911ì  ì¶©ì¡± ëª©í‘œ)
        west_center_df_search = valid_centers_df[valid_centers_df["ì„¼í„°ëª…"].str.contains("ì„œë¶€ì„¼í„°", case=False, na=False)]
        if not west_center_df_search.empty:
            west_center_df = west_center_df_search.iloc[0:1]
            west_total_score = west_center_df["ì´ì  (Max 1000ì )"].iloc[0]
            st.markdown(f"#### ğŸ¯ **'ì„œë¶€ì„¼í„°' 911ì  ì¶©ì¡± ë¶„ì„**")
            st.info(f"**ì„œë¶€ì„¼í„°**ì˜ **ì˜ˆì¸¡ ì´ì **ì€ **{west_total_score}ì **ì…ë‹ˆë‹¤. "
                    f"Gap **{gap_ratio}%**ì™€ ì ˆëŒ€ ê³„ì•½ë¥  **{abs_rate_ratio}%**ì˜ í˜¼í•© ë¹„ìœ¨ì„ ì¡°ì ˆí•˜ì—¬ {west_total_score}ì ì´ 911ì  ì´ìƒì´ ë˜ë„ë¡ ë§ì¶°ë³´ì„¸ìš”.")
        
        # 6-3. ì‹œê°í™” 1: ê³„ì•½ë¥  ì˜ˆì¸¡ ì¶”ì´ vs 2026ë…„ ëª©í‘œ
        st.markdown("---")
        st.subheader(f"3. ì„¼í„°ë³„ ê³„ì•½ë¥  ì¶”ì´ ë° {target_year}ë…„ 12ì›” ì˜ˆì¸¡ ê²°ê³¼ (ë¡œì§€ìŠ¤í‹± ì„±ì¥ ê³¡ì„ )")
        
        pred_col_float = target_year + 11/12
        plot_cols_names = rate_cols_sorted + [predicted_col_name]
        
        plot_data_trend = data_merged.set_index("ì„¼í„°ëª…")[plot_cols_names].T
        
        plot_data_trend = plot_data_trend.drop(columns=[c for c in plot_data_trend.columns if 'í•©ê³„' in c.lower() or 'ì´ê³„' in c.lower()], errors='ignore')

        plot_data_trend.index = [extract_year_month(col)[0] + extract_year_month(col)[1]/12 if 'ì˜ˆì¸¡' not in col else pred_col_float for col in plot_data_trend.index]
        
        fig, ax = plt.subplots(figsize=(14, 7))
        for col in plot_data_trend.columns:
            past_data = plot_data_trend[col].iloc[:-1]
            ax.plot(past_data.index, past_data.values, marker='o', linestyle='-', alpha=0.6, label=col)
            
            # ì˜ˆì¸¡ ë°ì´í„°ëŠ” ì ì„ 
            pred_data = plot_data_trend[col].iloc[-2:]
            ax.plot(pred_data.index, pred_data.values, marker='x', linestyle='--', alpha=0.7, color=ax.lines[-1].get_color())

        # 2026ë…„ ëª©í‘œì„ 
        ax.axhline(y=GOALS[2026], color='red', linestyle=':', linewidth=2, label=f'2026ë…„ KPI ëª©í‘œ ({GOALS[2026]:.1f}%)')
        
        ax.set_title(f"ì„¼í„°ë³„ ëˆ„ì  ì‚¬ìš©ê³„ì•½ë¥  ì¶”ì´ ë° {target_year}ë…„ 12ì›” ì˜ˆì¸¡")
        ax.set_ylabel("ì‚¬ìš©ê³„ì•½ë¥  (%)")
        ax.set_xlabel("ê¸°ê°„")
        ax.grid(axis='y', linestyle='--', alpha=0.5)
        
        x_ticks_labels = rate_cols_sorted + [f"{target_year}ë…„ 12ì›” ì˜ˆì¸¡"]
        x_ticks_values = [extract_year_month(col)[0] + extract_year_month(col)[1]/12 for col in rate_cols_sorted] + [pred_col_float]
        ax.set_xticks(x_ticks_values)
        ax.set_xticklabels(x_ticks_labels, rotation=45, ha='right')

        handles, labels = ax.get_legend_handles_labels()
        unique_labels = dict(zip(labels, handles))
        ax.legend(unique_labels.values(), unique_labels.keys(), loc='upper left', ncol=3, fontsize='small')
        
        plt.tight_layout()
        st.pyplot(fig)


        # 6-4. ì‹œê°í™” 2: ì´ì  ë° 911ì  ë‹¬ì„± íˆíŠ¸ë§µ
        st.markdown("---")
        st.subheader("4. ì„¼í„°ë³„ ì´ì  ë° 911ì  ë‹¬ì„± í˜„í™© (íˆíŠ¸ë§µ)")
        
        plot_data_heatmap = valid_centers_df[["ì„¼í„°ëª…", "ì´ì  (Max 1000ì )"]].set_index("ì„¼í„°ëª…")
        colors = valid_centers_df["911ì  ë„ë‹¬ ì—¬ë¶€"].map({"âœ… ë„ë‹¬": 'green', "âŒ ìœ„í—˜": 'red'}).tolist()

        fig2, ax3 = plt.subplots(figsize=(12, 6))
        
        bars = ax3.bar(plot_data_heatmap.index, plot_data_heatmap["ì´ì  (Max 1000ì )"], color=colors)
        
        ax3.axhline(y=911, color='blue', linestyle='--', linewidth=2, label='ê³„ì•½ ìœ ì§€ ê¸°ì¤€ (911ì )')
        
        ax3.set_title(f'ì„¼í„°ë³„ ìµœì¢… ì´ì  ë° 911ì  ë‹¬ì„± í˜„í™© (2026ë…„ ì˜ˆì¸¡ ê¸°ë°˜, í˜¼í•© í‰ê°€ì§€í‘œ ë°˜ì˜)')
        ax3.set_ylabel("ìµœì¢… ì´ì  (Max 1000ì )")
        ax3.set_xlabel("ê³ ê°ì„¼í„°")
        ax3.set_ylim(min(plot_data_heatmap["ì´ì  (Max 1000ì )"].min() * 0.9, 800), 1000)
        
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        st.pyplot(fig2)


        # 6-5. ë‹¤ìš´ë¡œë“œ
        st.markdown("---")
        st.subheader("5. ê²°ê³¼ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
        
        download_df_final = data_merged.merge(valid_centers_df.drop(columns=["ì˜ˆì¸¡ê³„ì•½ë¥ "]), on="ì„¼í„°ëª…", how="inner")
        
        rate_cols_in_df = [c for c in download_df_final.columns if c in rate_cols_sorted]
        score_cols_to_keep = OTHER_SCORE_COLUMNS + ["ê¸°íƒ€ ì§€í‘œ ì´ì  (Max 900ì )", "Gap(%)", "Gap ê¸°ì¤€ ì ìˆ˜", "ì ˆëŒ€ ê³„ì•½ë¥  ê¸°ì¤€ ì ìˆ˜", "ì‚¬ìš©ê³„ì•½ë¥  ì ìˆ˜ (Max 100ì )", "ì´ì  (Max 1000ì )", "911ì  ë„ë‹¬ ì—¬ë¶€"]
        
        final_download_cols = (
            ["ì„¼í„°ëª…"] + rate_cols_in_df + [predicted_col_name] + 
            [c for c in download_df_final.columns if c in OTHER_SCORE_COLUMNS] + 
            [c for c in score_cols_to_keep if c in download_df_final.columns and c not in OTHER_SCORE_COLUMNS] 
        )
        final_download_df = download_df_final[final_download_cols]

        csv = final_download_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", data=csv, 
                           file_name=f"ì‚¬ìš©ê³„ì•½ë¥ _í‰ê°€ì‹œë®¬ë ˆì´ì…˜_V4.0_í˜¼í•©í‰ê°€ì§€í‘œ_ê²°ê³¼.csv", mime="text/csv")
        
        st.markdown(f"""
        ---
        ### ğŸ’¡ ì •ì±…ì  ì œì–¸ ë° ë¶„ì„ ê²°ê³¼ ìš”ì•½
        - **Gap ë¹„ìœ¨ ({gap_ratio}%)**ê³¼ **ì ˆëŒ€ ê³„ì•½ë¥  ë¹„ìœ¨ ({abs_rate_ratio}%)**ì„ í˜¼í•©í•˜ì—¬ **ì‚¬ìš©ê³„ì•½ë¥  ì ìˆ˜ (Max 100ì )**ë¥¼ ì‚°ì •í–ˆìŠµë‹ˆë‹¤.
        - **'ì„œë¶€ì„¼í„°'**ì˜ **ì˜ˆì¸¡ ì´ì **ì´ **911ì **ì„ ì¶©ì¡±í•˜ëŠ”ì§€ í™•ì¸í•˜ë©´ì„œ **ë‘ ë¹„ìœ¨ì„ ì¡°ì •**í•˜ëŠ” ê²ƒì´ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ìµœì ì˜ ë°©ì•ˆì´ ë  ê²ƒì…ë‹ˆë‹¤.
        - **Gap í‰ê°€ì§€í‘œ**ëŠ” **ë…¸ë ¥ ëŒ€ë¹„ ì„±ê³¼**ë¥¼, **ì ˆëŒ€ ê³„ì•½ë¥  ì§€í‘œ**ëŠ” **ì„¼í„°ì˜ ê¸°ë°˜ ê²½ìŸë ¥**ì„ ë°˜ì˜í•˜ëŠ” ë° ìœ ë¦¬í•©ë‹ˆë‹¤.
        ---
        """)

    else:
        st.info("ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì‚¬ì´ë“œë°”ì˜ í‰ê°€ ê¸°ì¤€ ë° ì‹¤ì ì„ ì„¤ì •í•˜ë©´ ì‹œë®¬ë ˆì´ì…˜ì´ ì‹œì‘ë©ë‹ˆë‹¤.")
